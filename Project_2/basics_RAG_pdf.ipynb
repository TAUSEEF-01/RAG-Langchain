{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad9b4b85-9d17-468c-b244-73a1c5191e3e",
   "metadata": {},
   "source": [
    "# RAG application built on Gemini (Dynamic Multi-PDF Input)\n",
    "\n",
    "You can provide multiple `pdf_urls` or local paths; all will be loaded, chunked, embedded, and queried together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772942ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 'pdf_paths' may be defined later (multi). Fallback to single pdf_path.\n",
    "if 'pdf_paths' in globals():\n",
    "    all_data = []\n",
    "    for p in pdf_paths:\n",
    "        loader = PyPDFLoader(str(p))\n",
    "        all_data.extend(loader.load())\n",
    "    data = all_data\n",
    "else:\n",
    "    loader = PyPDFLoader(str(pdf_path))\n",
    "    data = loader.load()  # entire PDF is loaded as a single Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct list of PDF paths from environment (PDF_PATHS) if provided\n",
    "import os, pathlib\n",
    "if 'pdf_paths' not in globals():\n",
    "    env_multi = os.getenv('PDF_PATHS','')\n",
    "    pdf_paths = []\n",
    "    if env_multi:\n",
    "        for part in env_multi.split('|'):\n",
    "            p = pathlib.Path(part)\n",
    "            if p.exists():\n",
    "                pdf_paths.append(p)\n",
    "    # Ensure at least the single pdf_path if available\n",
    "    if 'pdf_path' in globals() and pdf_path not in pdf_paths:\n",
    "        pdf_paths = [pdf_path] + pdf_paths\n",
    "print(f\"PDF count for embedding: {len(pdf_paths)}\")\n",
    "for p in pdf_paths: print(' -', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d49c22a-1ad0-4395-b93b-aa95660aa026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(str(pdf_path))\n",
    "data = loader.load()  # entire PDF is loaded as a single Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a374eb7c-e262-42bb-8f3f-308ba7dcdbe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29633e3b-ff24-4ace-a09b-c03b6e28c5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents:  115\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# split data\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
    "docs = text_splitter.split_documents(data)\n",
    "\n",
    "\n",
    "print(\"Total number of documents: \",len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "100b7d1a-1209-49d4-99ed-c51bc233a938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Adobe PDF Library 20.6.74', 'creator': 'Acrobat PDFMaker 20 for PowerPoint', 'creationdate': '2024-09-23T21:04:11+06:00', 'moddate': '2025-01-08T07:46:38+06:00', 'title': 'Theory of Computation', 'author': 'Md Mosaddek Khan', 'source': 'Automata.pdf', 'total_pages': 114, 'page': 7, 'page_label': '8'}, page_content='Basics of Strings \\nMMK@CSEDU')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1073ab7f-2632-4367-8dec-c19449d6ce71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05168594419956207,\n",
       " -0.030764883384108543,\n",
       " -0.03062233328819275,\n",
       " -0.02802734263241291,\n",
       " 0.01813093200325966]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a per-multi-PDF persist directory (hash of filenames + sizes)\n",
    "from hashlib import sha1\n",
    "sig = ';'.join(sorted(f\"{p.name}:{p.stat().st_size}\" for p in pdf_paths if p.exists()))\n",
    "persist_dir = f\"chroma_store_{sha1(sig.encode()).hexdigest()[:8]}\"\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"),\n",
    "    persist_directory=persist_dir,\n",
    ")\n",
    "vectorstore.persist()\n",
    "print(f\"Vector store persisted to: {persist_dir} for {len(pdf_paths)} PDF(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b6e6a-d8ab-41fb-a665-b72c9c9b4026",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})  # reduce k to cut context tokens\n",
    "print(f\"Retriever ready for {len(pdf_paths)} PDF(s)\")\n",
    "retrieved_docs = retriever.invoke(\"What is an automata? Explain with an example.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c674c5c-1b57-42e9-a99d-9e882c75da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})  # reduce k to cut context tokens\n",
    "print(f\"Retriever ready for: {pdf_path}\")\n",
    "retrieved_docs = retriever.invoke(\"What is an automata? Explain with an example.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04c5c6bb-fd0e-45ec-b315-e3f7656e0329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f991a1f-6ce9-4463-9941-b35014df94f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using chat model: gemini-2.0-flash\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "\n",
    "# Prefer a lighter / cheaper model by default to reduce quota exhaustion.\n",
    "# You can override via environment variable GEMINI_CHAT_MODEL.\n",
    "model_name = os.getenv(\"GEMINI_CHAT_MODEL\", \"gemini-2.0-flash\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=model_name,\n",
    "    temperature=0.3,\n",
    "    max_output_tokens=400,  # slightly lower to save quota\n",
    ")\n",
    "print(f\"Using chat model: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ee17439-7bc3-4931-9f57-4ec7e82ce902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "266e86e0-746b-4943-9470-fd842633ed85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG chain ready (retriever k=5)\n"
     ]
    }
   ],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "print(\"RAG chain ready (retriever k=5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9db9500d-4c51-4a10-9b21-f1ef9c8f985e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An automata, also known as a Finite State Machine, consists of states and transitions (edges) between these states. An edge label defines the move from one state to another. There are three types of Finite Automata: Deterministic Finite Automata (DFA), Non-deterministic Finite Automata (NFA), and Finite Automata with ε-transitions (ε-NFA).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from google.api_core.exceptions import ResourceExhausted\n",
    "\n",
    "QUERY = \"What is an automata? Explain with an example.\"\n",
    "\n",
    "def safe_ask(query: str, retries: int = 3):\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            return rag_chain.invoke({\"input\": query})\n",
    "        except ResourceExhausted as e:\n",
    "            if attempt == retries:\n",
    "                raise\n",
    "            # Extract suggested server backoff if present, else exponential fallback\n",
    "            delay = 5 * attempt\n",
    "            print(f\"Quota hit (attempt {attempt}/{retries}). Backing off {delay}s...\")\n",
    "            time.sleep(delay)\n",
    "\n",
    "response = safe_ask(QUERY)\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242ba20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask arbitrary questions against the loaded PDF\n",
    "USER_QUERY = \"Summarize the main topic of this document.\"  # change this\n",
    "resp = safe_ask(USER_QUERY)\n",
    "print(resp[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
